<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Decision Trees – Data Mining</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./ch2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch3.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Mining</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Data Mining</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">What is Statistical Learing?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#motivational-example-dataset" id="toc-motivational-example-dataset" class="nav-link active" data-scroll-target="#motivational-example-dataset"><span class="header-section-number">3.1</span> Motivational Example Dataset</a>
  <ul class="collapse">
  <li><a href="#predictor-space" id="toc-predictor-space" class="nav-link" data-scroll-target="#predictor-space"><span class="header-section-number">3.1.1</span> Predictor space</a></li>
  <li><a href="#decision-tree" id="toc-decision-tree" class="nav-link" data-scroll-target="#decision-tree"><span class="header-section-number">3.1.2</span> Decision Tree</a></li>
  <li><a href="#partition-space" id="toc-partition-space" class="nav-link" data-scroll-target="#partition-space"><span class="header-section-number">3.1.3</span> Partition space</a></li>
  </ul></li>
  <li><a href="#parts-of-a-decision-tree" id="toc-parts-of-a-decision-tree" class="nav-link" data-scroll-target="#parts-of-a-decision-tree"><span class="header-section-number">3.2</span> Parts of a decision tree</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">3.3</span> Introduction</a></li>
  <li><a href="#decision-trees-regression---finding-the-best-split-and-best-splitting-variable" id="toc-decision-trees-regression---finding-the-best-split-and-best-splitting-variable" class="nav-link" data-scroll-target="#decision-trees-regression---finding-the-best-split-and-best-splitting-variable"><span class="header-section-number">3.4</span> Decision Trees: Regression - Finding the best split and best splitting variable</a></li>
  <li><a href="#recursive-partitioning-for-regression-trees" id="toc-recursive-partitioning-for-regression-trees" class="nav-link" data-scroll-target="#recursive-partitioning-for-regression-trees"><span class="header-section-number">3.5</span> Recursive Partitioning for Regression Trees</a></li>
  <li><a href="#recursive-partitioning-for-regression-trees-1" id="toc-recursive-partitioning-for-regression-trees-1" class="nav-link" data-scroll-target="#recursive-partitioning-for-regression-trees-1"><span class="header-section-number">3.6</span> Recursive Partitioning for Regression Trees</a>
  <ul class="collapse">
  <li><a href="#step-1-start-with-all-predictors" id="toc-step-1-start-with-all-predictors" class="nav-link" data-scroll-target="#step-1-start-with-all-predictors"><span class="header-section-number">3.6.1</span> Step 1: Start with All Predictors</a></li>
  <li><a href="#step-2-consider-all-possible-values" id="toc-step-2-consider-all-possible-values" class="nav-link" data-scroll-target="#step-2-consider-all-possible-values"><span class="header-section-number">3.6.2</span> Step 2: Consider All Possible Values</a></li>
  <li><a href="#step-3-choose-the-best-split" id="toc-step-3-choose-the-best-split" class="nav-link" data-scroll-target="#step-3-choose-the-best-split"><span class="header-section-number">3.6.3</span> Step 3: Choose the Best Split</a></li>
  <li><a href="#step-4-recursive-partitioning" id="toc-step-4-recursive-partitioning" class="nav-link" data-scroll-target="#step-4-recursive-partitioning"><span class="header-section-number">3.6.4</span> Step 4: Recursive Partitioning</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">3.6.5</span> Summary</a></li>
  </ul></li>
  <li><a href="#depth-of-the-decision-tree" id="toc-depth-of-the-decision-tree" class="nav-link" data-scroll-target="#depth-of-the-decision-tree"><span class="header-section-number">3.7</span> Depth of the decision tree</a></li>
  <li><a href="#pruning-regression-trees" id="toc-pruning-regression-trees" class="nav-link" data-scroll-target="#pruning-regression-trees"><span class="header-section-number">3.8</span> Pruning Regression Trees</a>
  <ul class="collapse">
  <li><a href="#why-prune" id="toc-why-prune" class="nav-link" data-scroll-target="#why-prune"><span class="header-section-number">3.8.1</span> Why Prune?</a></li>
  <li><a href="#types-of-pruning" id="toc-types-of-pruning" class="nav-link" data-scroll-target="#types-of-pruning"><span class="header-section-number">3.8.2</span> Types of Pruning</a></li>
  <li><a href="#cost-complexity-pruning-a.k.a.-weakest-link-pruning" id="toc-cost-complexity-pruning-a.k.a.-weakest-link-pruning" class="nav-link" data-scroll-target="#cost-complexity-pruning-a.k.a.-weakest-link-pruning"><span class="header-section-number">3.8.3</span> Cost Complexity Pruning (a.k.a. Weakest Link Pruning)</a></li>
  <li><a href="#interpretation-of-parameters" id="toc-interpretation-of-parameters" class="nav-link" data-scroll-target="#interpretation-of-parameters"><span class="header-section-number">3.8.4</span> Interpretation of Parameters</a></li>
  <li><a href="#total-cost-components" id="toc-total-cost-components" class="nav-link" data-scroll-target="#total-cost-components"><span class="header-section-number">3.8.5</span> Total Cost Components</a></li>
  </ul></li>
  <li><a href="#example-r-code-for-pre-pruning-and-post-pruning" id="toc-example-r-code-for-pre-pruning-and-post-pruning" class="nav-link" data-scroll-target="#example-r-code-for-pre-pruning-and-post-pruning"><span class="header-section-number">3.9</span> Example R code for Pre-pruning and Post-pruning</a></li>
  <li><a href="#classification-trees-best-split-entropy-and-gini-coefficients" id="toc-classification-trees-best-split-entropy-and-gini-coefficients" class="nav-link" data-scroll-target="#classification-trees-best-split-entropy-and-gini-coefficients"><span class="header-section-number">3.10</span> Classification Trees: Best Split, Entropy, and Gini Coefficients</a>
  <ul class="collapse">
  <li><a href="#the-idea-of-best-split" id="toc-the-idea-of-best-split" class="nav-link" data-scroll-target="#the-idea-of-best-split"><span class="header-section-number">3.10.1</span> The Idea of “Best Split”</a></li>
  <li><a href="#entropy" id="toc-entropy" class="nav-link" data-scroll-target="#entropy"><span class="header-section-number">3.10.2</span> Entropy</a></li>
  <li><a href="#gini-index" id="toc-gini-index" class="nav-link" data-scroll-target="#gini-index"><span class="header-section-number">3.10.3</span> Gini Index</a></li>
  <li><a href="#misclassification-error-less-common" id="toc-misclassification-error-less-common" class="nav-link" data-scroll-target="#misclassification-error-less-common"><span class="header-section-number">3.10.4</span> Misclassification Error (less common)</a></li>
  <li><a href="#choosing-the-best-split" id="toc-choosing-the-best-split" class="nav-link" data-scroll-target="#choosing-the-best-split"><span class="header-section-number">3.10.5</span> Choosing the Best Split</a></li>
  <li><a href="#comparing-entropy-and-gini" id="toc-comparing-entropy-and-gini" class="nav-link" data-scroll-target="#comparing-entropy-and-gini"><span class="header-section-number">3.10.6</span> Comparing Entropy and Gini</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="motivational-example-dataset" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="motivational-example-dataset"><span class="header-section-number">3.1</span> Motivational Example Dataset</h2>
<p>Features: Sepal Length, Sepal Width</p>
<p>Outcome: Species: setosa/versicolor</p>
<section id="predictor-space" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="predictor-space"><span class="header-section-number">3.1.1</span> Predictor space</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-1-1.png" style="height:70.0%" width="672" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-tree" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="decision-tree"><span class="header-section-number">3.1.2</span> Decision Tree</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="partition-space" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="partition-space"><span class="header-section-number">3.1.3</span> Partition space</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(R1 = \{X|Sepal.Width &gt;=3, Sepal.Length &lt;5.5
\}\)</span></p>
</section>
</section>
<section id="parts-of-a-decision-tree" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="parts-of-a-decision-tree"><span class="header-section-number">3.2</span> Parts of a decision tree</h2>
<ul>
<li><p>Root node</p></li>
<li><p>Decision node</p></li>
<li><p>Terminal node/ Leaf node (gives outputs/class assignments)</p></li>
<li><p>Subtree</p></li>
</ul>
</section>
<section id="introduction" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="introduction"><span class="header-section-number">3.3</span> Introduction</h2>
<p>What happens in the model training phase?</p>
<ul>
<li><p>Stratify or segment the predictor space into a number of non-overlapping regions.</p></li>
<li><p>Set of splitting rules are used to segment the predictor space.</p></li>
<li><p>Decision tree consists of a series of splitting rules.</p></li>
</ul>
<p>How to make predictions?</p>
<ul>
<li><p>Mean or mode response value for the training observations in the region which the observation we want to predict belong to.</p></li>
<li><p>We make the same prediction, for the training observations in the <span class="math inline">\(j^{th}\)</span> region <span class="math inline">\(R_j\)</span>.</p></li>
</ul>
</section>
<section id="decision-trees-regression---finding-the-best-split-and-best-splitting-variable" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="decision-trees-regression---finding-the-best-split-and-best-splitting-variable"><span class="header-section-number">3.4</span> Decision Trees: Regression - Finding the best split and best splitting variable</h2>
<p>The goal is to find <span class="math inline">\(R_1, R_2, R_3...R_J\)</span>, <span class="math inline">\(J\)</span> distinct and non-overlapping regions that minimize the RSS given by</p>
<p><span class="math display">\[\sum_{j=1}^{J}\sum_{i \in R_j}(y_i - \hat{y}_{R_j})^2.\]</span> <span class="math inline">\(\hat{y}_{R_j}\)</span> - mean response for the training observations within the <span class="math inline">\(j^{th}\)</span> region.</p>
<p>In theory, to build the best possible decision tree, we could try every possible way of splitting the data at every step and choose the one that gives the best results. However, this is computationally infeasible, especially when the dataset is large or when there are many predictor variables — the number of possible splits grows exponentially.</p>
<p>Therefore, instead of trying all possible combinations at once, we use a <strong>recursive partitioning approach</strong>. This means:</p>
<p>Start with the entire dataset as one group (the root node).</p>
<p>Find the single best split — the one that most effectively separates the data based on the target variable.</p>
<p>Divide the data into two or more subgroups (child nodes) based on that split.</p>
<p>Repeat the process (recursively) within each subgroup: again find the best split, divide the data, and continue until a stopping rule is met (for example, minimum node size or maximum tree depth).</p>
<p>This recursive process allows the algorithm to build the tree step by step, finding locally optimal splits that approximate the best possible tree without having to evaluate every possible combination.</p>
</section>
<section id="recursive-partitioning-for-regression-trees" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="recursive-partitioning-for-regression-trees"><span class="header-section-number">3.5</span> Recursive Partitioning for Regression Trees</h2>
<p>A regression tree predicts a continuous outcome (for example, house price, temperature, or pH level). The goal is to split the data into smaller and smaller groups (nodes) that are as homogeneous as possible with respect to the response variable.</p>
<p>In-class notation</p>
</section>
<section id="recursive-partitioning-for-regression-trees-1" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="recursive-partitioning-for-regression-trees-1"><span class="header-section-number">3.6</span> Recursive Partitioning for Regression Trees</h2>
<p>A <strong>regression tree</strong> is used when the response variable is <em>continuous</em> (e.g., house price, temperature, or pH level).</p>
<p>The goal is to split the data into smaller and smaller groups (nodes) that are as <strong>homogeneous as possible</strong> with respect to the response.</p>
<section id="step-1-start-with-all-predictors" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="step-1-start-with-all-predictors"><span class="header-section-number">3.6.1</span> Step 1: Start with All Predictors</h3>
<p>At the beginning, the algorithm considers <strong>all predictor variables</strong>:</p>
<p><span class="math display">\[X_1, X_2, X_3, \dots, X_p\]</span></p>
<p>For each predictor, it looks for the <strong>best split point</strong> that divides the data into two groups such that the prediction error (usually the <strong>sum of squared errors, SSE</strong>) is minimized.</p>
</section>
<section id="step-2-consider-all-possible-values" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="step-2-consider-all-possible-values"><span class="header-section-number">3.6.2</span> Step 2: Consider All Possible Values</h3>
<section id="continuous-predictors" class="level4" data-number="3.6.2.1">
<h4 data-number="3.6.2.1" class="anchored" data-anchor-id="continuous-predictors"><span class="header-section-number">3.6.2.1</span> Continuous predictors</h4>
<p>If a predictor <span class="math inline">\(X_j\)</span> is <strong>continuous</strong>,<br>
then “all possible values” refers to <strong>all unique values</strong> (or <strong>midpoints between consecutive sorted values</strong>) that can be used to split the data.</p>
<p>Example:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Observation</th>
<th><span class="math inline">\(X_j\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>2</td>
<td>3</td>
</tr>
<tr class="odd">
<td>3</td>
<td>5</td>
</tr>
<tr class="even">
<td>4</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>Possible split points (midpoints): - <span class="math inline">\(X_j &lt; 2.5\)</span> - <span class="math inline">\(X_j &lt; 4\)</span> - <span class="math inline">\(X_j &lt; 6\)</span></p>
<p>Each of these potential splits is tested to see how well it reduces the SSE of the response variable.</p>
</section>
<section id="categorical-predictors" class="level4" data-number="3.6.2.2">
<h4 data-number="3.6.2.2" class="anchored" data-anchor-id="categorical-predictors"><span class="header-section-number">3.6.2.2</span> Categorical predictors</h4>
<p>If <span class="math inline">\(X_j\)</span> is <strong>categorical</strong>,<br>
“all possible values” means all possible <strong>groupings (subsets)</strong> of the categories.</p>
<p>Example:<br>
If the predictor <code>Species</code> = {A, B, C}, possible splits are:</p>
<ul>
<li><p>{A} vs {B, C}</p></li>
<li><p>{B} vs {A, C}</p></li>
<li><p>{C} vs {A, B}</p></li>
</ul>
<p>Each grouping is evaluated based on how much it reduces the variability in the response.</p>
</section>
</section>
<section id="step-3-choose-the-best-split" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="step-3-choose-the-best-split"><span class="header-section-number">3.6.3</span> Step 3: Choose the Best Split</h3>
<p>For every predictor and every possible split value, compute:</p>
<p><span class="math display">\[
\text{SSE}_{\text{split}} = \text{SSE}_{\text{left node}} + \text{SSE}_{\text{right node}}
\]</span></p>
<p>The <strong>split that minimizes</strong> this total SSE is chosen as the best split for that node.</p>
</section>
<section id="step-4-recursive-partitioning" class="level3" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="step-4-recursive-partitioning"><span class="header-section-number">3.6.4</span> Step 4: Recursive Partitioning</h3>
<p>After splitting the data into two nodes, the same process is applied <strong>recursively</strong> within each node:</p>
<ol type="1">
<li>Consider all predictors again.<br>
</li>
<li>For each predictor, test all possible values.<br>
</li>
<li>Find the best split within that node.<br>
</li>
<li>Continue until a stopping rule is met (e.g., minimum node size or no significant improvement).</li>
</ol>
</section>
<section id="summary" class="level3" data-number="3.6.5">
<h3 data-number="3.6.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">3.6.5</span> Summary</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 41%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th>Concept</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>All predictors</strong></td>
<td>Every variable <span class="math inline">\(X_1, X_2, \dots, X_p\)</span> is considered at each split.</td>
</tr>
<tr class="even">
<td><strong>All possible values</strong></td>
<td>Every unique value (or midpoint between values) is tested as a potential split.</td>
</tr>
<tr class="odd">
<td><strong>Recursive partitioning</strong></td>
<td>The process of repeatedly splitting the data into smaller homogeneous groups until a stopping rule is met.</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p><strong>In summary:</strong><br>
Finding every possible combination of splits is computationally infeasible.<br>
Recursive partitioning provides a practical, step-by-step method that finds locally optimal splits efficiently.</p>
</blockquote>
</section>
</section>
<section id="depth-of-the-decision-tree" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="depth-of-the-decision-tree"><span class="header-section-number">3.7</span> Depth of the decision tree</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-5-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-6-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="pruning-regression-trees" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="pruning-regression-trees"><span class="header-section-number">3.8</span> Pruning Regression Trees</h2>
<p>Once a regression tree is grown, it often becomes <strong>too complex</strong> — it may fit the training data very well but perform poorly on new, unseen data.<br>
This problem is known as <strong>overfitting</strong>.</p>
<p><strong>Pruning</strong> is the process of <strong>reducing the size</strong> of a fully grown tree to improve its ability to generalize.</p>
<section id="why-prune" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="why-prune"><span class="header-section-number">3.8.1</span> Why Prune?</h3>
<ul>
<li>A large tree captures <strong>noise</strong> as if it were structure.<br>
</li>
<li>It has <strong>low bias</strong> but <strong>high variance</strong>.<br>
</li>
<li>Pruning helps to find a <strong>balance between model complexity and prediction accuracy</strong>.</li>
</ul>
</section>
<section id="types-of-pruning" class="level3" data-number="3.8.2">
<h3 data-number="3.8.2" class="anchored" data-anchor-id="types-of-pruning"><span class="header-section-number">3.8.2</span> Types of Pruning</h3>
<p>There are two main approaches:</p>
<section id="a-pre-pruning-early-stopping" class="level4" data-number="3.8.2.1">
<h4 data-number="3.8.2.1" class="anchored" data-anchor-id="a-pre-pruning-early-stopping"><span class="header-section-number">3.8.2.1</span> (a) Pre-pruning (Early stopping)</h4>
<p>Stop the tree growth <strong>before</strong> it becomes too large.</p>
<p>Common stopping rules:</p>
<ul>
<li><p>Minimum number of observations in a node</p></li>
<li><p>Maximum tree depth</p></li>
<li><p>Minimum decrease in SSE required for a split</p></li>
</ul>
</section>
<section id="b-post-pruning-cost-complexity-pruning" class="level4" data-number="3.8.2.2">
<h4 data-number="3.8.2.2" class="anchored" data-anchor-id="b-post-pruning-cost-complexity-pruning"><span class="header-section-number">3.8.2.2</span> (b) Post-pruning (Cost Complexity Pruning)</h4>
<p>Grow a <strong>large tree first</strong>, then prune it <strong>backward</strong> by removing branches that contribute little to predictive accuracy.</p>
</section>
</section>
<section id="cost-complexity-pruning-a.k.a.-weakest-link-pruning" class="level3" data-number="3.8.3">
<h3 data-number="3.8.3" class="anchored" data-anchor-id="cost-complexity-pruning-a.k.a.-weakest-link-pruning"><span class="header-section-number">3.8.3</span> Cost Complexity Pruning (a.k.a. Weakest Link Pruning)</h3>
<p>The idea is to penalize tree size using a complexity parameter (<span class="math inline">\(\lambda\)</span>).</p>
<p>For any subtree ( T ):</p>
<p><span class="math display">\[
C(T) = \text{Error}(T) + \lambda L(T)
\]</span></p>
<p>where:</p>
<ul>
<li>(T): measure of fit (e.g., sum of squared errors)<br>
</li>
<li><span class="math inline">\(L(T)\)</span>: number of leaf nodes in the tree (measure of complexity)<br>
</li>
<li><span class="math inline">\(\lambda\)</span>: penalty factor controlling the trade-off between complexity and predictive power</li>
</ul>
</section>
<section id="interpretation-of-parameters" class="level3" data-number="3.8.4">
<h3 data-number="3.8.4" class="anchored" data-anchor-id="interpretation-of-parameters"><span class="header-section-number">3.8.4</span> Interpretation of Parameters</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 54%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\lambda = 0\)</span></td>
<td>Fully grown decision tree (no penalty for complexity).</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\lambda = \infty\)</span></td>
<td>Root node only (maximum penalty, no splits).</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0 &lt; \lambda &lt; \infty\)</span></td>
<td>Balances predictive power and complexity.</td>
</tr>
</tbody>
</table>
</section>
<section id="total-cost-components" class="level3" data-number="3.8.5">
<h3 data-number="3.8.5" class="anchored" data-anchor-id="total-cost-components"><span class="header-section-number">3.8.5</span> Total Cost Components</h3>
<p><span class="math display">\[
\text{Total Cost} = \text{Measure of Fit} + \text{Measure of Complexity}
\]</span></p>
<ul>
<li><strong>Measure of Fit:</strong> Error (e.g., SSE)<br>
</li>
<li><strong>Measure of Complexity:</strong> Number of leaf nodes <span class="math inline">\(L(T)\)</span></li>
</ul>
<p>So, <span class="math display">\[
C(T) = \text{Error}(T) + \lambda L(T)
\]</span></p>
<p>This is sometimes written as:</p>
<p><span class="math display">\[
R_\lambda(T) = R(T) + \lambda |T|
\]</span></p>
<p>Both expressions represent the same concept — a <strong>trade-off between model fit and simplicity</strong>.</p>
</section>
</section>
<section id="example-r-code-for-pre-pruning-and-post-pruning" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="example-r-code-for-pre-pruning-and-post-pruning"><span class="header-section-number">3.9</span> Example R code for Pre-pruning and Post-pruning</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Use built-in dataset</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 🌱 1. Pre-pruning (Early stopping)</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Control parameters limit tree growth</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>prepruned_tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  mpg <span class="sc">~</span> ., </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> mtcars,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"anova"</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">minsplit =</span> <span class="dv">10</span>,   <span class="co"># minimum observations required to attempt a split</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">cp =</span> <span class="fl">0.02</span>,       <span class="co"># minimum improvement in SSE required for a split</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">maxdepth =</span> <span class="dv">3</span>     <span class="co"># maximum depth of the tree</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the pre-pruned tree</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(prepruned_tree, <span class="at">main =</span> <span class="st">"Pre-pruned Regression Tree"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print summary</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(prepruned_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>n= 32 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 32 1126.047000 20.09062  
   2) wt&gt;=2.26 26  346.566500 17.78846  
     4) cyl&gt;=7 14   85.200000 15.10000  
       8) disp&gt;=420 3   12.326670 11.83333 *
       9) disp&lt; 420 11   32.129090 15.99091 *
     5) cyl&lt; 7 12   42.122500 20.92500  
      10) wt&gt;=3.3275 3    1.086667 18.36667 *
      11) wt&lt; 3.3275 9   14.855560 21.77778 *
   3) wt&lt; 2.26 6   44.553330 30.06667 *</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(prepruned_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
rpart(formula = mpg ~ ., data = mtcars, method = "anova", control = rpart.control(minsplit = 10, 
    cp = 0.02, maxdepth = 3))
  n= 32 

          CP nsplit rel error    xerror       xstd
1 0.65266121      0 1.0000000 1.0863063 0.26519210
2 0.19470235      1 0.3473388 0.6852332 0.16791734
3 0.03618342      2 0.1526364 0.3430358 0.10012133
4 0.02324972      3 0.1164530 0.2957831 0.07419667
5 0.02000000      4 0.0932033 0.2887422 0.07322052

Variable importance
  wt disp   hp drat  cyl qsec   vs 
  27   25   19   11    9    5    5 

Node number 1: 32 observations,    complexity param=0.6526612
  mean=20.09062, MSE=35.18897 
  left son=2 (26 obs) right son=3 (6 obs)
  Primary splits:
      wt   &lt; 2.26   to the right, improve=0.6526612, (0 missing)
      cyl  &lt; 5      to the right, improve=0.6431252, (0 missing)
      disp &lt; 163.8  to the right, improve=0.6130502, (0 missing)
      hp   &lt; 118    to the right, improve=0.6010712, (0 missing)
      vs   &lt; 0.5    to the left,  improve=0.4409477, (0 missing)
  Surrogate splits:
      disp &lt; 101.55 to the right, agree=0.969, adj=0.833, (0 split)
      hp   &lt; 92     to the right, agree=0.938, adj=0.667, (0 split)
      drat &lt; 4      to the left,  agree=0.906, adj=0.500, (0 split)
      cyl  &lt; 5      to the right, agree=0.844, adj=0.167, (0 split)

Node number 2: 26 observations,    complexity param=0.1947024
  mean=17.78846, MSE=13.32948 
  left son=4 (14 obs) right son=5 (12 obs)
  Primary splits:
      cyl  &lt; 7      to the right, improve=0.6326174, (0 missing)
      disp &lt; 266.9  to the right, improve=0.6326174, (0 missing)
      hp   &lt; 136.5  to the right, improve=0.5803554, (0 missing)
      wt   &lt; 3.325  to the right, improve=0.5393370, (0 missing)
      qsec &lt; 18.15  to the left,  improve=0.4210605, (0 missing)
  Surrogate splits:
      disp &lt; 266.9  to the right, agree=1.000, adj=1.000, (0 split)
      hp   &lt; 136.5  to the right, agree=0.962, adj=0.917, (0 split)
      wt   &lt; 3.49   to the right, agree=0.885, adj=0.750, (0 split)
      qsec &lt; 18.15  to the left,  agree=0.885, adj=0.750, (0 split)
      vs   &lt; 0.5    to the left,  agree=0.885, adj=0.750, (0 split)

Node number 3: 6 observations
  mean=30.06667, MSE=7.425556 

Node number 4: 14 observations,    complexity param=0.03618342
  mean=15.1, MSE=6.085714 
  left son=8 (3 obs) right son=9 (11 obs)
  Primary splits:
      disp &lt; 420    to the right, improve=0.4782188, (0 missing)
      wt   &lt; 4.66   to the right, improve=0.4782188, (0 missing)
      hp   &lt; 192.5  to the right, improve=0.4669349, (0 missing)
      carb &lt; 3.5    to the right, improve=0.4669349, (0 missing)
      qsec &lt; 17.71  to the right, improve=0.4306658, (0 missing)
  Surrogate splits:
      wt   &lt; 4.66   to the right, agree=1.000, adj=1.000, (0 split)
      drat &lt; 3.035  to the left,  agree=0.857, adj=0.333, (0 split)
      qsec &lt; 17.41  to the right, agree=0.857, adj=0.333, (0 split)

Node number 5: 12 observations,    complexity param=0.02324972
  mean=20.925, MSE=3.510208 
  left son=10 (3 obs) right son=11 (9 obs)
  Primary splits:
      wt   &lt; 3.3275 to the right, improve=0.6215272, (0 missing)
      cyl  &lt; 5      to the right, improve=0.5573591, (0 missing)
      hp   &lt; 96     to the right, improve=0.5507811, (0 missing)
      disp &lt; 163.8  to the right, improve=0.4615111, (0 missing)
      carb &lt; 3      to the right, improve=0.2857431, (0 missing)
  Surrogate splits:
      disp &lt; 163.8  to the right, agree=0.917, adj=0.667, (0 split)
      hp   &lt; 116.5  to the right, agree=0.833, adj=0.333, (0 split)

Node number 8: 3 observations
  mean=11.83333, MSE=4.108889 

Node number 9: 11 observations
  mean=15.99091, MSE=2.920826 

Node number 10: 3 observations
  mean=18.36667, MSE=0.3622222 

Node number 11: 9 observations
  mean=21.77778, MSE=1.650617 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 🌳 2. Post-pruning (Cost-complexity pruning)</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Grow a large tree first</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>full_tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  mpg <span class="sc">~</span> ., </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> mtcars,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"anova"</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">cp =</span> <span class="fl">0.0001</span>)  <span class="co"># allow the tree to grow large</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Display complexity parameter (CP) table</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(full_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression tree:
rpart(formula = mpg ~ ., data = mtcars, method = "anova", control = rpart.control(cp = 1e-04))

Variables actually used in tree construction:
[1] cyl hp 

Root node error: 1126/32 = 35.189

n= 32 

        CP nsplit rel error  xerror    xstd
1 0.643125      0   1.00000 1.02606 0.24552
2 0.097484      1   0.35687 0.64743 0.16940
3 0.000100      2   0.25939 0.53811 0.12137</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Plot cross-validation results</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(full_tree, <span class="at">main =</span> <span class="st">"Cost-Complexity Pruning Plot"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-7-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Select the cp value that minimizes cross-validation error</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>optimal_cp <span class="ot">&lt;-</span> full_tree<span class="sc">$</span>cptable[<span class="fu">which.min</span>(full_tree<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>]), <span class="st">"CP"</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Prune the tree at the optimal cp value</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="ot">&lt;-</span> <span class="fu">prune</span>(full_tree, <span class="at">cp =</span> optimal_cp)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Visualize the pruned tree</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(pruned_tree, <span class="at">main =</span> <span class="st">"Post-pruned Regression Tree"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-7-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 7: Summarize pruned model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pruned_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
rpart(formula = mpg ~ ., data = mtcars, method = "anova", control = rpart.control(cp = 1e-04))
  n= 32 

          CP nsplit rel error    xerror      xstd
1 0.64312523      0 1.0000000 1.0260596 0.2455202
2 0.09748407      1 0.3568748 0.6474280 0.1694045
3 0.00010000      2 0.2593907 0.5381142 0.1213682

Variable importance
 cyl disp   hp   wt qsec   vs carb 
  20   20   19   16   12   11    1 

Node number 1: 32 observations,    complexity param=0.6431252
  mean=20.09062, MSE=35.18897 
  left son=2 (21 obs) right son=3 (11 obs)
  Primary splits:
      cyl  &lt; 5      to the right, improve=0.6431252, (0 missing)
      wt   &lt; 2.3925 to the right, improve=0.6356630, (0 missing)
      disp &lt; 163.8  to the right, improve=0.6130502, (0 missing)
      hp   &lt; 118    to the right, improve=0.6010712, (0 missing)
      vs   &lt; 0.5    to the left,  improve=0.4409477, (0 missing)
  Surrogate splits:
      disp &lt; 142.9  to the right, agree=0.969, adj=0.909, (0 split)
      hp   &lt; 101    to the right, agree=0.938, adj=0.818, (0 split)
      wt   &lt; 2.5425 to the right, agree=0.906, adj=0.727, (0 split)
      qsec &lt; 18.41  to the left,  agree=0.844, adj=0.545, (0 split)
      vs   &lt; 0.5    to the left,  agree=0.844, adj=0.545, (0 split)

Node number 2: 21 observations,    complexity param=0.09748407
  mean=16.64762, MSE=9.451066 
  left son=4 (7 obs) right son=5 (14 obs)
  Primary splits:
      hp   &lt; 192.5  to the right, improve=0.5530828, (0 missing)
      cyl  &lt; 7      to the right, improve=0.5068475, (0 missing)
      disp &lt; 266.9  to the right, improve=0.5068475, (0 missing)
      wt   &lt; 3.49   to the right, improve=0.4414890, (0 missing)
      drat &lt; 3.075  to the left,  improve=0.1890739, (0 missing)
  Surrogate splits:
      disp &lt; 334    to the right, agree=0.857, adj=0.571, (0 split)
      wt   &lt; 4.66   to the right, agree=0.810, adj=0.429, (0 split)
      qsec &lt; 15.455 to the left,  agree=0.810, adj=0.429, (0 split)
      carb &lt; 3.5    to the right, agree=0.762, adj=0.286, (0 split)
      gear &lt; 4.5    to the right, agree=0.714, adj=0.143, (0 split)

Node number 3: 11 observations
  mean=26.66364, MSE=18.48959 

Node number 4: 7 observations
  mean=13.41429, MSE=4.118367 

Node number 5: 14 observations
  mean=18.26429, MSE=4.276582 </code></pre>
</div>
</div>
</section>
<section id="classification-trees-best-split-entropy-and-gini-coefficients" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="classification-trees-best-split-entropy-and-gini-coefficients"><span class="header-section-number">3.10</span> Classification Trees: Best Split, Entropy, and Gini Coefficients</h2>
<p>Classification trees are used when the response variable is <strong>categorical</strong>.<br>
At each node, the algorithm tries to find the <strong>best split</strong> — the one that produces the most <strong>homogeneous</strong> (pure) child nodes.</p>
<section id="the-idea-of-best-split" class="level3" data-number="3.10.1">
<h3 data-number="3.10.1" class="anchored" data-anchor-id="the-idea-of-best-split"><span class="header-section-number">3.10.1</span> The Idea of “Best Split”</h3>
<p>At any node in the tree:</p>
<ul>
<li>The data are divided into two (or more) groups based on a predictor.</li>
<li>The <strong>best split</strong> is the one that makes each resulting group as <strong>pure</strong> as possible with respect to the class labels.</li>
</ul>
<p>To measure <strong>purity</strong>, we use <strong>impurity measures</strong> such as:</p>
<ul>
<li><p><strong>Entropy</strong></p></li>
<li><p><strong>Gini index</strong></p></li>
<li><p>(Sometimes) <strong>Misclassification error</strong></p></li>
</ul>
</section>
<section id="entropy" class="level3" data-number="3.10.2">
<h3 data-number="3.10.2" class="anchored" data-anchor-id="entropy"><span class="header-section-number">3.10.2</span> Entropy</h3>
<p>Entropy measures the <strong>disorder</strong> or <strong>uncertainty</strong> in a node.</p>
<p>If there are ( K ) classes and ( p_k ) is the proportion of observations belonging to class ( k ), then:</p>
<p><span class="math display">\[
\text{Entropy} = - \sum_{k=1}^{K} p_k \log_2(p_k)
\]</span></p>
<section id="properties" class="level4" data-number="3.10.2.1">
<h4 data-number="3.10.2.1" class="anchored" data-anchor-id="properties"><span class="header-section-number">3.10.2.1</span> Properties:</h4>
<ul>
<li>Entropy = 0 → Node is perfectly pure (all observations belong to one class).</li>
<li>Entropy is maximum when all classes are equally likely.</li>
</ul>
</section>
<section id="example" class="level4" data-number="3.10.2.2">
<h4 data-number="3.10.2.2" class="anchored" data-anchor-id="example"><span class="header-section-number">3.10.2.2</span> Example:</h4>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Class</th>
<th>Count</th>
<th><span class="math inline">\(p_k\)</span></th>
<th><span class="math inline">\(-p_k \log_2(p_k)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>8</td>
<td>0.8</td>
<td>0.257</td>
</tr>
<tr class="even">
<td>B</td>
<td>2</td>
<td>0.2</td>
<td>0.464</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\text{Entropy} = 0.257 + 0.464 = 0.721
\]</span></p>
</section>
</section>
<section id="gini-index" class="level3" data-number="3.10.3">
<h3 data-number="3.10.3" class="anchored" data-anchor-id="gini-index"><span class="header-section-number">3.10.3</span> Gini Index</h3>
<p>The <strong>Gini coefficient</strong> (or <strong>Gini impurity</strong>) is another measure of node impurity.</p>
<p><span class="math display">\[
\text{Gini} = 1 - \sum_{k=1}^{K} p_k^2
\]</span></p>
<section id="properties-1" class="level4" data-number="3.10.3.1">
<h4 data-number="3.10.3.1" class="anchored" data-anchor-id="properties-1"><span class="header-section-number">3.10.3.1</span> Properties:</h4>
<ul>
<li><p>Gini = 0 → Perfectly pure node</p></li>
<li><p>Gini is smaller when the node is more homogeneous</p></li>
</ul>
</section>
<section id="example-1" class="level4" data-number="3.10.3.2">
<h4 data-number="3.10.3.2" class="anchored" data-anchor-id="example-1"><span class="header-section-number">3.10.3.2</span> Example:</h4>
<p>Using the same proportions as above ( <span class="math inline">\(p_1 = 0.8, p_2 = 0.2\)</span> ):</p>
<p><span class="math display">\[
\text{Gini} = 1 - (0.8^2 + 0.2^2) = 1 - (0.64 + 0.04) = 0.32
\]</span></p>
</section>
</section>
<section id="misclassification-error-less-common" class="level3" data-number="3.10.4">
<h3 data-number="3.10.4" class="anchored" data-anchor-id="misclassification-error-less-common"><span class="header-section-number">3.10.4</span> Misclassification Error (less common)</h3>
<p>A simpler impurity measure sometimes used:</p>
<p><span class="math display">\[
\text{Error} = 1 - \max(p_k)
\]</span></p>
<p>For the same node ( <span class="math inline">\(\max(p_k) = 0.8\)</span> ):</p>
<p><span class="math display">\[
\text{Error} = 1 - 0.8 = 0.2
\]</span></p>
</section>
<section id="choosing-the-best-split" class="level3" data-number="3.10.5">
<h3 data-number="3.10.5" class="anchored" data-anchor-id="choosing-the-best-split"><span class="header-section-number">3.10.5</span> Choosing the Best Split</h3>
<p>For each possible split:</p>
<ol type="1">
<li><p>Compute the impurity (Entropy or Gini) <strong>before</strong> splitting — call this <span class="math inline">\(I_{\text{parent}}\)</span>.</p></li>
<li><p>Compute the impurity of the <strong>child nodes</strong> (weighted by their sizes):</p></li>
</ol>
<p><span class="math display">\[
I_{\text{split}} = \frac{n_L}{n} I_L + \frac{n_R}{n} I_R
\]</span></p>
<ol start="3" type="1">
<li>Compute the <strong>information gain</strong> (reduction in impurity):</li>
</ol>
<p><span class="math display">\[
\text{Gain} = I_{\text{parent}} - I_{\text{split}}
\]</span></p>
<ol start="4" type="1">
<li>The <strong>best split</strong> is the one that maximizes this gain (i.e., gives the largest reduction in impurity).</li>
</ol>
</section>
<section id="comparing-entropy-and-gini" class="level3" data-number="3.10.6">
<h3 data-number="3.10.6" class="anchored" data-anchor-id="comparing-entropy-and-gini"><span class="header-section-number">3.10.6</span> Comparing Entropy and Gini</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 37%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Property</th>
<th>Entropy</th>
<th>Gini</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Range</td>
<td>0 to 1</td>
<td>0 to 0.5</td>
</tr>
<tr class="even">
<td>Shape</td>
<td>Logarithmic</td>
<td>Quadratic</td>
</tr>
<tr class="odd">
<td>Interpretation</td>
<td>Information theory measure</td>
<td>Probability of misclassification</td>
</tr>
<tr class="even">
<td>Behavior</td>
<td>Slightly more sensitive to rare classes</td>
<td>Computationally simpler</td>
</tr>
<tr class="odd">
<td>Commonly used in</td>
<td>C4.5, ID3 algorithms</td>
<td>CART algorithm</td>
</tr>
</tbody>
</table>
<p>Both criteria often lead to <strong>similar splits</strong> in practice.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch2.html" class="pagination-link" aria-label="What is Statistical Learing?">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">What is Statistical Learing?</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>