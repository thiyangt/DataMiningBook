\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\newlabel{preface}{{}{3}{}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{Preface}{3}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction to Data Mining}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction-to-data-mining}{{1}{4}{Introduction to Data Mining}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is Data Mining?}{4}{section.1.1}\protected@file@percent }
\newlabel{what-is-data-mining}{{1.1}{4}{What is Data Mining?}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}What do we mean by interesting patterns?}{4}{section.1.2}\protected@file@percent }
\newlabel{what-do-we-mean-by-interesting-patterns}{{1.2}{4}{What do we mean by interesting patterns?}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Characteristics of Big Data: 5 V's of Big Data}{4}{section.1.3}\protected@file@percent }
\newlabel{characteristics-of-big-data-5-vs-of-big-data}{{1.3}{4}{Characteristics of Big Data: 5 V's of Big Data}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}What motivates the development of data mining field?}{5}{section.1.4}\protected@file@percent }
\newlabel{what-motivates-the-development-of-data-mining-field}{{1.4}{5}{What motivates the development of data mining field?}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Data Mining Tasks}{5}{section.1.5}\protected@file@percent }
\newlabel{data-mining-tasks}{{1.5}{5}{Data Mining Tasks}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Data Quality}{5}{section.1.6}\protected@file@percent }
\newlabel{data-quality}{{1.6}{5}{Data Quality}{section.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Applications}{5}{section.1.7}\protected@file@percent }
\newlabel{applications}{{1.7}{5}{Applications}{section.1.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}What is Statistical Learing?}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{what-is-statistical-learing}{{2}{6}{What is Statistical Learing?}{chapter.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Decision Trees}{7}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{decision-trees}{{3}{7}{Decision Trees}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivational Example Dataset}{7}{section.3.1}\protected@file@percent }
\newlabel{motivational-example-dataset}{{3.1}{7}{Motivational Example Dataset}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Predictor space}{7}{subsection.3.1.1}\protected@file@percent }
\newlabel{predictor-space}{{3.1.1}{7}{Predictor space}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Decision Tree}{8}{subsection.3.1.2}\protected@file@percent }
\newlabel{decision-tree}{{3.1.2}{8}{Decision Tree}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Partition space}{9}{subsection.3.1.3}\protected@file@percent }
\newlabel{partition-space}{{3.1.3}{9}{Partition space}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Parts of a decision tree}{10}{section.3.2}\protected@file@percent }
\newlabel{parts-of-a-decision-tree}{{3.2}{10}{Parts of a decision tree}{section.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Introduction}{10}{section.3.3}\protected@file@percent }
\newlabel{introduction}{{3.3}{10}{Introduction}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Decision Trees: Regression - Finding the best split and best splitting variable}{10}{section.3.4}\protected@file@percent }
\newlabel{decision-trees-regression---finding-the-best-split-and-best-splitting-variable}{{3.4}{10}{Decision Trees: Regression - Finding the best split and best splitting variable}{section.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Recursive Partitioning for Regression Trees}{11}{section.3.5}\protected@file@percent }
\newlabel{recursive-partitioning-for-regression-trees}{{3.5}{11}{Recursive Partitioning for Regression Trees}{section.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Recursive Partitioning for Regression Trees}{11}{section.3.6}\protected@file@percent }
\newlabel{recursive-partitioning-for-regression-trees-1}{{3.6}{11}{Recursive Partitioning for Regression Trees}{section.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Step 1: Start with All Predictors}{11}{subsection.3.6.1}\protected@file@percent }
\newlabel{step-1-start-with-all-predictors}{{3.6.1}{11}{Step 1: Start with All Predictors}{subsection.3.6.1}{}}
\gdef \LT@i {\LT@entry 
    {1}{63.58606pt}\LT@entry 
    {1}{19.19217pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Step 2: Consider All Possible Values}{12}{subsection.3.6.2}\protected@file@percent }
\newlabel{step-2-consider-all-possible-values}{{3.6.2}{12}{Step 2: Consider All Possible Values}{subsection.3.6.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2.1}Continuous predictors}{12}{subsubsection.3.6.2.1}\protected@file@percent }
\newlabel{continuous-predictors}{{3.6.2.1}{12}{Continuous predictors}{subsubsection.3.6.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2.2}Categorical predictors}{12}{subsubsection.3.6.2.2}\protected@file@percent }
\newlabel{categorical-predictors}{{3.6.2.2}{12}{Categorical predictors}{subsubsection.3.6.2.2}{}}
\gdef \LT@ii {\LT@entry 
    {1}{187.16548pt}\LT@entry 
    {1}{259.59454pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Step 3: Choose the Best Split}{13}{subsection.3.6.3}\protected@file@percent }
\newlabel{step-3-choose-the-best-split}{{3.6.3}{13}{Step 3: Choose the Best Split}{subsection.3.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Step 4: Recursive Partitioning}{13}{subsection.3.6.4}\protected@file@percent }
\newlabel{step-4-recursive-partitioning}{{3.6.4}{13}{Step 4: Recursive Partitioning}{subsection.3.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Summary}{13}{subsection.3.6.5}\protected@file@percent }
\newlabel{summary}{{3.6.5}{13}{Summary}{subsection.3.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Depth of the decision tree}{14}{section.3.7}\protected@file@percent }
\newlabel{depth-of-the-decision-tree}{{3.7}{14}{Depth of the decision tree}{section.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Pruning Regression Trees}{16}{section.3.8}\protected@file@percent }
\newlabel{pruning-regression-trees}{{3.8}{16}{Pruning Regression Trees}{section.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Why Prune?}{16}{subsection.3.8.1}\protected@file@percent }
\newlabel{why-prune}{{3.8.1}{16}{Why Prune?}{subsection.3.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.2}Types of Pruning}{16}{subsection.3.8.2}\protected@file@percent }
\newlabel{types-of-pruning}{{3.8.2}{16}{Types of Pruning}{subsection.3.8.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.2.1}(a) Pre-pruning (Early stopping)}{16}{subsubsection.3.8.2.1}\protected@file@percent }
\newlabel{a-pre-pruning-early-stopping}{{3.8.2.1}{16}{(a) Pre-pruning (Early stopping)}{subsubsection.3.8.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.2.2}(b) Post-pruning (Cost Complexity Pruning)}{16}{subsubsection.3.8.2.2}\protected@file@percent }
\newlabel{b-post-pruning-cost-complexity-pruning}{{3.8.2.2}{16}{(b) Post-pruning (Cost Complexity Pruning)}{subsubsection.3.8.2.2}{}}
\gdef \LT@iii {\LT@entry 
    {1}{243.16234pt}\LT@entry 
    {1}{203.59769pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.3}Cost Complexity Pruning (a.k.a. Weakest Link Pruning)}{17}{subsection.3.8.3}\protected@file@percent }
\newlabel{cost-complexity-pruning-a.k.a.-weakest-link-pruning}{{3.8.3}{17}{Cost Complexity Pruning (a.k.a. Weakest Link Pruning)}{subsection.3.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.4}Interpretation of Parameters}{17}{subsection.3.8.4}\protected@file@percent }
\newlabel{interpretation-of-parameters}{{3.8.4}{17}{Interpretation of Parameters}{subsection.3.8.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.5}Total Cost Components}{17}{subsection.3.8.5}\protected@file@percent }
\newlabel{total-cost-components}{{3.8.5}{17}{Total Cost Components}{subsection.3.8.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Example R code for Pre-pruning and Post-pruning}{18}{section.3.9}\protected@file@percent }
\newlabel{example-r-code-for-pre-pruning-and-post-pruning}{{3.9}{18}{Example R code for Pre-pruning and Post-pruning}{section.3.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Classification Trees: Best Split, Entropy, and Gini Coefficients}{25}{section.3.10}\protected@file@percent }
\newlabel{classification-trees-best-split-entropy-and-gini-coefficients}{{3.10}{25}{Classification Trees: Best Split, Entropy, and Gini Coefficients}{section.3.10}{}}
\gdef \LT@iv {\LT@entry 
    {1}{31.0536pt}\LT@entry 
    {1}{41.51025pt}\LT@entry 
    {3}{25.99411pt}\LT@entry 
    {1}{65.03986pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.1}The Idea of ``Best Split''}{26}{subsection.3.10.1}\protected@file@percent }
\newlabel{the-idea-of-best-split}{{3.10.1}{26}{The Idea of ``Best Split''}{subsection.3.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.2}Entropy}{26}{subsection.3.10.2}\protected@file@percent }
\newlabel{entropy}{{3.10.2}{26}{Entropy}{subsection.3.10.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.2.1}Properties:}{26}{subsubsection.3.10.2.1}\protected@file@percent }
\newlabel{properties}{{3.10.2.1}{26}{Properties:}{subsubsection.3.10.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.2.2}Example:}{26}{subsubsection.3.10.2.2}\protected@file@percent }
\newlabel{example}{{3.10.2.2}{26}{Example:}{subsubsection.3.10.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.3}Gini Index}{27}{subsection.3.10.3}\protected@file@percent }
\newlabel{gini-index}{{3.10.3}{27}{Gini Index}{subsection.3.10.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.3.1}Properties:}{27}{subsubsection.3.10.3.1}\protected@file@percent }
\newlabel{properties-1}{{3.10.3.1}{27}{Properties:}{subsubsection.3.10.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.3.2}Example:}{27}{subsubsection.3.10.3.2}\protected@file@percent }
\newlabel{example-1}{{3.10.3.2}{27}{Example:}{subsubsection.3.10.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.4}Misclassification Error (less common)}{27}{subsection.3.10.4}\protected@file@percent }
\newlabel{misclassification-error-less-common}{{3.10.4}{27}{Misclassification Error (less common)}{subsection.3.10.4}{}}
\gdef \LT@v {\LT@entry 
    {1}{178.23007pt}\LT@entry 
    {1}{168.5933pt}\LT@entry 
    {1}{99.93663pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.5}Choosing the Best Split}{28}{subsection.3.10.5}\protected@file@percent }
\newlabel{choosing-the-best-split}{{3.10.5}{28}{Choosing the Best Split}{subsection.3.10.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.6}Comparing Entropy and Gini}{28}{subsection.3.10.6}\protected@file@percent }
\newlabel{comparing-entropy-and-gini}{{3.10.6}{28}{Comparing Entropy and Gini}{subsection.3.10.6}{}}
